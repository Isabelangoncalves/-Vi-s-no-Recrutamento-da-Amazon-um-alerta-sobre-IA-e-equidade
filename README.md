# Viés no Recrutamento da Amazon: um alerta sobre IA e equidade

O caso da IA de recrutamento da Amazon expôs um problema grave: o sistema favorecia candidatos homens, ignorando currículos femininos igualmente qualificados. Isso ocorreu porque o algoritmo foi treinado com dados antigos e enviesados, sem diversidade de gênero, etnia ou contexto social.

Além da falta de justiça, o sistema falhava em transparência — nem os próprios recrutadores sabiam explicar os critérios de aprovação. Isso gerou impactos sociais sérios, reforçando desigualdades e dificultando o direito à contestação.

🔍 Minha análise aponta que:

A IA deveria ter sido testada com perfis diversos.

Faltou governança ética e responsabilidade no design.

Explicações claras sobre reprovações são essenciais.

✅ Minha posição final: sistemas de IA precisam ser justos, explicáveis e inclusivos. Recrutamento automatizado só funciona se respeitar os princípios de equidade e transparência.


#IAÉtica #DiversidadeNoTrabalho #TransparênciaAlgorítmica #RecrutamentoJusto #TechResponsável


